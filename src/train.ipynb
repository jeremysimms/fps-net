{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.all import *\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the paths to each of the datasets. \n",
    "\n",
    "The training root folder should be composed of 2 subfolders, one for the training set and one for the validation set. The training set use used to adjust the weights of the model, and the validation set is used to assess the loss after each training epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_root = \"/data/\"\n",
    "test_root = \"/test/\"\n",
    "training_set_folder = \"train\"\n",
    "validation_set_folder = \"val\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a datablock and data loaders\n",
    "\n",
    "```\n",
    "GrandparentSplitter(train_name=training_set_folder, valid_name=validation_set_folder),\n",
    "```\n",
    "This tells the data block that the training and validation sets both exist in separate folders called `training_set_folder` and `validation_set_folder`\n",
    "\n",
    "```\n",
    "get_items=get_image_files,\n",
    "```\n",
    "Defines how the datablock loads the files, in this case we just load every image in the target directory.\n",
    "\n",
    "```\n",
    "get_y=parent_label,\n",
    "```\n",
    "This tells the datablock that each class label exists as a subfolder underneath the validation and training set folders.\n",
    "\n",
    "```\n",
    "batch_tfms=aug_transforms(size=224),\n",
    "```\n",
    "Defines a set of data augmentations on each input image during the training phase. Randomizes croping, warping etc in order to get more robust results and reduce overfitting. These run on the GPU during training.\n",
    "\n",
    "```\n",
    "item_tfms=[Resize(600, method='squish')]\n",
    "```\n",
    "Item transformations are run by the CPU prior to sending them to the GPU. Here we need all the images to be the same size so we squish to a max of 600px.\n",
    "\n",
    "```\n",
    ".dataloaders(training_root, bs=64)\n",
    "```\n",
    "Converts the block definition to a dataloader and sets the batch size to 64. Batch size is the number of images pushed to the GPU at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock), \n",
    "    get_items=get_image_files, \n",
    "    splitter=GrandparentSplitter(train_name=training_set_folder, valid_name=validation_set_folder),\n",
    "    get_y=parent_label,\n",
    "    batch_tfms=aug_transforms(size=224),\n",
    "    item_tfms=[Resize(600, method='squish')]\n",
    ").dataloaders(training_root, bs=64)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show a batch of Test Data\n",
    "\n",
    "Just to examine what the image augmentations are doing and what our data set looks like, here we load a few images at random and inspect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.show_batch(max_n=12)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the learner\n",
    "\n",
    "Here we load a resnet50 pretrained model and pass it our data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = vision_learner(dls, resnet50, metrics=error_rate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "Now we fine tine the model for 4 epochs. Fine tuning resets a few of the top layers of the model without erasing all of the weights from lower layers. For image classification this generally reduces the amount of training time since the model is already set up do do things like recognize edges, and sets of smaller features that will help our model.\n",
    "\n",
    "A training epoch involves taking each batch of the training set and using it to adjust the weights of the top few layers we're fine tuning, then measuring the loss using the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fine_tune(4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting results\n",
    "\n",
    "In order to have some visibility into where our model had problems, we create an interpretation and then plot the top losses that occurred during validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = Interpretation.from_learner(learn)\n",
    "interp.plot_top_losses(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing against a separate dataset\n",
    "\n",
    "Create a test dataset and validate against it. Test data should be structured like the training set but without a separate validation set.\n",
    "So the root should look like this:\n",
    "\n",
    "- /test_root\n",
    "    - valorant\n",
    "    - not_valorant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = learn.dls.test_dl(get_image_files(test_root), with_labels=True, shuffle=True)\n",
    "learn.validate(dl=test_dl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
